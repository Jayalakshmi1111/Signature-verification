{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n",
      "250\n",
      "(250, 200, 500)\n",
      "(250, 200, 500)\n",
      "     label\n",
      "0        1\n",
      "1        1\n",
      "2        0\n",
      "3        1\n",
      "4        1\n",
      "..     ...\n",
      "245      0\n",
      "246      0\n",
      "247      0\n",
      "248      1\n",
      "249      1\n",
      "\n",
      "[250 rows x 1 columns]\n",
      "[[[255 255 255 ... 255 255 255]\n",
      "  [255 255 255 ... 255 255 255]\n",
      "  [255 255 255 ... 255 255 255]\n",
      "  ...\n",
      "  [255 255 255 ... 255 255 255]\n",
      "  [255 255 255 ... 255 255 255]\n",
      "  [255 255 255 ... 255 255 255]]\n",
      "\n",
      " [[255 255 255 ... 255 255 255]\n",
      "  [255 255 255 ... 255 255 255]\n",
      "  [255 255 255 ... 255 255 255]\n",
      "  ...\n",
      "  [255 255 255 ... 255 255 255]\n",
      "  [255 255 255 ... 255 255 255]\n",
      "  [255 255 255 ... 255 255 255]]\n",
      "\n",
      " [[255 255 255 ... 255 255 255]\n",
      "  [255 255 255 ... 255 255 255]\n",
      "  [255 255 255 ... 255 255 255]\n",
      "  ...\n",
      "  [255 255 255 ... 255 255 255]\n",
      "  [255 255 255 ... 255 255 255]\n",
      "  [255 255 255 ... 255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255 255 255 ... 255 255 255]\n",
      "  [255 255 255 ... 255 255 255]\n",
      "  [255 255 255 ... 255 255 255]\n",
      "  ...\n",
      "  [255 255 255 ... 255 255 255]\n",
      "  [255 255 255 ... 255 255 255]\n",
      "  [255 255 255 ... 255 255 255]]\n",
      "\n",
      " [[255 255 255 ... 255 255 255]\n",
      "  [255 255 255 ... 255 255 255]\n",
      "  [255 255 255 ... 255 255 255]\n",
      "  ...\n",
      "  [255 255 255 ... 255 255 255]\n",
      "  [255 255 255 ... 255 255 255]\n",
      "  [255 255 255 ... 255 255 255]]\n",
      "\n",
      " [[255 255 255 ... 255 255 255]\n",
      "  [255 255 255 ... 255 255 255]\n",
      "  [255 255 255 ... 255 255 255]\n",
      "  ...\n",
      "  [255 255 255 ... 255 255 255]\n",
      "  [255 255 255 ... 255 255 255]\n",
      "  [255 255 255 ... 255 255 255]]]\n"
     ]
    }
   ],
   "source": [
    "#importing required library\n",
    "import keras\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "#%%\n",
    "#preprocessing the image datas\n",
    "file_dir1 = 'C:/Users/JAYALAKSHMI/Downloads/input1/input1/*'\n",
    "file_dir2 = 'C:/Users/JAYALAKSHMI/Downloads/input2-_1_ (1)/input2/*'\n",
    "files = glob.glob(file_dir1)\n",
    "print(len(files))\n",
    "file2 = glob.glob(file_dir2)\n",
    "print(len(file2))\n",
    "\n",
    "    \n",
    "x1 = []\n",
    "for f1 in files:\n",
    "  img_dir = os.path.join(f1)\n",
    "  #print('img_dir',img_dir)\n",
    "  images = glob.glob(img_dir)\n",
    "  for img in images:\n",
    "    img_temp = cv2.imread(img,cv2.IMREAD_GRAYSCALE)\n",
    "    #img = cv2.resize(img,dim,ingerpolation = cv2.INTER_AREA)\n",
    "    img_temp = cv2.resize(img_temp,(500,200))\n",
    "    img_temo = img_temp/255\n",
    "    x1.append(img_temp)\n",
    "import numpy as np\n",
    "x1 = np.array(x1)\n",
    "print(x1.shape)\n",
    "\n",
    "#%%\n",
    "#file2 = glob.glob(file_dir2)\n",
    "#print(len(file2))\n",
    "x2 = []\n",
    "for f1 in file2:\n",
    "  img_dir = os.path.join(f1)\n",
    "  #print('img_dir',img_dir)\n",
    "  images = glob.glob(img_dir)\n",
    "  for img in images:\n",
    "    img_temp = cv2.imread(img,cv2.IMREAD_GRAYSCALE)\n",
    "    img_temp = cv2.resize(img_temp,(500,200))\n",
    "    img_temo = img_temp/255\n",
    "    x2.append(img_temp)\n",
    "import numpy as np\n",
    "x2 = np.array(x2)\n",
    "print(x2.shape)\n",
    "#%%\n",
    "ylabel = 'C:/Users/JAYALAKSHMI/Downloads/ylabel.csv'\n",
    "y = pd.read_csv(ylabel)\n",
    "print(y)\n",
    "print(x1)\n",
    "#%%\n",
    "from sklearn.utils import shuffle\n",
    "x1,x2,y = shuffle(x1,x2,y,random_state=2)\n",
    "\n",
    "# splitting dataset into train test\n",
    "x1_train = x1[0:180]\n",
    "x1_train = x1_train.reshape(180,200,500,1)\n",
    "x1_val = x1[180:210]\n",
    "x1_val = x1_val.reshape(30,200,500,1)\n",
    "\n",
    "x2_train = x2[0:180]\n",
    "x2_train = x2_train.reshape(180,200,500,1)\n",
    "x2_val = x2[180:210]\n",
    "x2_val = x2_val.reshape(30,200,500,1)\n",
    "\n",
    "x1_test = x1[210 :]\n",
    "x1_test = x1_test.reshape(40,200,500,1)\n",
    "x2_test = x2[210 :]\n",
    "x2_test = x2_test.reshape(40,200,500,1)\n",
    "\n",
    "y_train = y[0:180]\n",
    "y_val = y[180:210]\n",
    "y_test = y[210 :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "def get_siamese_model(input_shape):\n",
    "    #input_shape = (200,500,1)\n",
    "    left_input=Input(input_shape)\n",
    "    right_input=Input(input_shape)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32,(10,10), activation='relu', input_shape=input_shape,\n",
    "                    kernel_regularizer=l2(0.01),bias_regularizer=l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(64,(7,7), activation='relu',\n",
    "                    kernel_regularizer=l2(0.01),bias_regularizer=l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(MaxPooling2D())   \n",
    "    model.add(Conv2D(64,(4,4), activation='relu', \n",
    "                    kernel_regularizer=l2(0.01),bias_regularizer=l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(128,(4,4), activation='relu',\n",
    "                    kernel_regularizer=l2(0.01),bias_regularizer=l2(0.01)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024,activation='sigmoid',kernel_regularizer=l2(0.01),bias_regularizer=l2(0.01)))\n",
    "    \n",
    "    encoded_l=model(left_input)\n",
    "    encoded_r=model(right_input)\n",
    "    \n",
    "    L1_layer = Lambda(lambda tensors:K.abs(tensors[0]-tensors[1]))\n",
    "    L1_distance=L1_layer([encoded_l,encoded_r])\n",
    "    \n",
    "    prediction=Dense(1,activation='sigmoid')(L1_distance)\n",
    "    \n",
    "    siamese_net1 = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "    return siamese_net1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training process\n",
      "...............................\n",
      "Train on 180 samples, validate on 30 samples\n",
      "Epoch 1/5\n",
      "180/180 [==============================] - ETA: 10:28 - loss: 22.3755 - accuracy: 0.40 - ETA: 8:41 - loss: 21.9424 - accuracy: 0.5000 - ETA: 7:37 - loss: 21.4127 - accuracy: 0.533 - ETA: 6:55 - loss: 20.8736 - accuracy: 0.550 - ETA: 6:27 - loss: 20.4187 - accuracy: 0.480 - ETA: 6:05 - loss: 19.8694 - accuracy: 0.466 - ETA: 5:45 - loss: 19.3404 - accuracy: 0.457 - ETA: 5:27 - loss: 18.8592 - accuracy: 0.425 - ETA: 5:12 - loss: 18.3594 - accuracy: 0.466 - ETA: 4:56 - loss: 17.8826 - accuracy: 0.440 - ETA: 4:42 - loss: 17.4186 - accuracy: 0.436 - ETA: 4:30 - loss: 16.9712 - accuracy: 0.450 - ETA: 4:16 - loss: 16.5510 - accuracy: 0.415 - ETA: 4:04 - loss: 16.1474 - accuracy: 0.400 - ETA: 3:51 - loss: 15.7590 - accuracy: 0.426 - ETA: 3:39 - loss: 15.3918 - accuracy: 0.437 - ETA: 3:27 - loss: 15.0414 - accuracy: 0.458 - ETA: 3:15 - loss: 14.7076 - accuracy: 0.455 - ETA: 3:04 - loss: 14.3908 - accuracy: 0.452 - ETA: 2:52 - loss: 14.0865 - accuracy: 0.450 - ETA: 2:41 - loss: 13.7947 - accuracy: 0.466 - ETA: 2:30 - loss: 13.5149 - accuracy: 0.481 - ETA: 2:19 - loss: 13.2474 - accuracy: 0.478 - ETA: 2:08 - loss: 12.9906 - accuracy: 0.475 - ETA: 1:57 - loss: 12.7432 - accuracy: 0.480 - ETA: 1:46 - loss: 12.5062 - accuracy: 0.484 - ETA: 1:36 - loss: 12.2756 - accuracy: 0.496 - ETA: 1:25 - loss: 12.0526 - accuracy: 0.500 - ETA: 1:14 - loss: 11.8413 - accuracy: 0.482 - ETA: 1:03 - loss: 11.6336 - accuracy: 0.500 - ETA: 53s - loss: 11.4336 - accuracy: 0.509 - ETA: 42s - loss: 11.2407 - accuracy: 0.51 - ETA: 31s - loss: 11.0532 - accuracy: 0.51 - ETA: 21s - loss: 10.8701 - accuracy: 0.52 - ETA: 10s - loss: 10.6942 - accuracy: 0.52 - 397s 2s/step - loss: 10.5244 - accuracy: 0.5222 - val_loss: 4.4389 - val_accuracy: 0.6667\n",
      "Epoch 2/5\n",
      "180/180 [==============================] - ETA: 5:55 - loss: 4.4025 - accuracy: 0.80 - ETA: 5:45 - loss: 4.3446 - accuracy: 0.70 - ETA: 5:38 - loss: 4.2813 - accuracy: 0.66 - ETA: 5:29 - loss: 4.2160 - accuracy: 0.70 - ETA: 5:16 - loss: 4.1654 - accuracy: 0.64 - ETA: 5:06 - loss: 4.1018 - accuracy: 0.66 - ETA: 4:57 - loss: 4.0456 - accuracy: 0.62 - ETA: 4:48 - loss: 3.9894 - accuracy: 0.67 - ETA: 4:38 - loss: 3.9362 - accuracy: 0.66 - ETA: 4:27 - loss: 3.8845 - accuracy: 0.66 - ETA: 4:16 - loss: 3.8405 - accuracy: 0.63 - ETA: 4:07 - loss: 3.7958 - accuracy: 0.61 - ETA: 3:56 - loss: 3.7489 - accuracy: 0.61 - ETA: 3:46 - loss: 3.7107 - accuracy: 0.61 - ETA: 3:37 - loss: 3.6680 - accuracy: 0.62 - ETA: 3:27 - loss: 3.6297 - accuracy: 0.62 - ETA: 3:17 - loss: 3.5898 - accuracy: 0.62 - ETA: 3:07 - loss: 3.5557 - accuracy: 0.62 - ETA: 2:57 - loss: 3.5152 - accuracy: 0.63 - ETA: 2:46 - loss: 3.4820 - accuracy: 0.62 - ETA: 2:36 - loss: 3.4478 - accuracy: 0.61 - ETA: 2:25 - loss: 3.4185 - accuracy: 0.60 - ETA: 2:15 - loss: 3.3901 - accuracy: 0.59 - ETA: 2:04 - loss: 3.3629 - accuracy: 0.59 - ETA: 1:54 - loss: 3.3354 - accuracy: 0.59 - ETA: 1:44 - loss: 3.3087 - accuracy: 0.58 - ETA: 1:33 - loss: 3.2842 - accuracy: 0.57 - ETA: 1:23 - loss: 3.2640 - accuracy: 0.55 - ETA: 1:12 - loss: 3.2385 - accuracy: 0.55 - ETA: 1:02 - loss: 3.2182 - accuracy: 0.54 - ETA: 51s - loss: 3.1951 - accuracy: 0.5419 - ETA: 41s - loss: 3.1740 - accuracy: 0.543 - ETA: 31s - loss: 3.1549 - accuracy: 0.539 - ETA: 20s - loss: 3.1353 - accuracy: 0.541 - ETA: 10s - loss: 3.1114 - accuracy: 0.554 - 387s 2s/step - loss: 3.0911 - accuracy: 0.5556 - val_loss: 2.4239 - val_accuracy: 0.5667\n",
      "Epoch 3/5\n",
      "180/180 [==============================] - ETA: 6:05 - loss: 2.4675 - accuracy: 0.20 - ETA: 5:49 - loss: 2.3627 - accuracy: 0.50 - ETA: 5:40 - loss: 2.3355 - accuracy: 0.46 - ETA: 5:31 - loss: 2.3616 - accuracy: 0.45 - ETA: 5:19 - loss: 2.3643 - accuracy: 0.44 - ETA: 5:09 - loss: 2.3314 - accuracy: 0.46 - ETA: 4:59 - loss: 2.3024 - accuracy: 0.48 - ETA: 4:48 - loss: 2.3037 - accuracy: 0.50 - ETA: 4:37 - loss: 2.3102 - accuracy: 0.46 - ETA: 4:27 - loss: 2.3084 - accuracy: 0.46 - ETA: 4:17 - loss: 2.3016 - accuracy: 0.47 - ETA: 4:07 - loss: 2.3000 - accuracy: 0.46 - ETA: 3:56 - loss: 2.3033 - accuracy: 0.46 - ETA: 3:46 - loss: 2.2904 - accuracy: 0.48 - ETA: 3:36 - loss: 2.2972 - accuracy: 0.45 - ETA: 3:25 - loss: 2.2919 - accuracy: 0.45 - ETA: 3:15 - loss: 2.2919 - accuracy: 0.43 - ETA: 3:05 - loss: 2.2819 - accuracy: 0.44 - ETA: 2:55 - loss: 2.2752 - accuracy: 0.44 - ETA: 2:44 - loss: 2.2650 - accuracy: 0.45 - ETA: 2:34 - loss: 2.2617 - accuracy: 0.43 - ETA: 2:24 - loss: 2.2511 - accuracy: 0.44 - ETA: 2:14 - loss: 2.2406 - accuracy: 0.44 - ETA: 2:03 - loss: 2.2400 - accuracy: 0.43 - ETA: 1:53 - loss: 2.2265 - accuracy: 0.45 - ETA: 1:43 - loss: 2.2132 - accuracy: 0.46 - ETA: 1:32 - loss: 2.2009 - accuracy: 0.46 - ETA: 1:22 - loss: 2.1920 - accuracy: 0.47 - ETA: 1:12 - loss: 2.1908 - accuracy: 0.45 - ETA: 1:01 - loss: 2.1786 - accuracy: 0.46 - ETA: 51s - loss: 2.1688 - accuracy: 0.4710 - ETA: 41s - loss: 2.1614 - accuracy: 0.475 - ETA: 30s - loss: 2.1476 - accuracy: 0.484 - ETA: 20s - loss: 2.1407 - accuracy: 0.494 - ETA: 10s - loss: 2.1425 - accuracy: 0.497 - 385s 2s/step - loss: 2.1365 - accuracy: 0.5056 - val_loss: 2.0429 - val_accuracy: 0.4333\n",
      "Epoch 4/5\n",
      "180/180 [==============================] - ETA: 5:59 - loss: 1.9412 - accuracy: 0.60 - ETA: 5:48 - loss: 1.9110 - accuracy: 0.80 - ETA: 5:36 - loss: 1.9420 - accuracy: 0.80 - ETA: 5:28 - loss: 1.9199 - accuracy: 0.85 - ETA: 5:18 - loss: 1.9438 - accuracy: 0.80 - ETA: 5:07 - loss: 1.9581 - accuracy: 0.80 - ETA: 4:58 - loss: 1.9766 - accuracy: 0.77 - ETA: 4:47 - loss: 1.9901 - accuracy: 0.72 - ETA: 4:37 - loss: 1.9991 - accuracy: 0.71 - ETA: 4:27 - loss: 2.0050 - accuracy: 0.72 - ETA: 4:17 - loss: 2.0062 - accuracy: 0.72 - ETA: 4:06 - loss: 2.0100 - accuracy: 0.73 - ETA: 3:57 - loss: 2.0168 - accuracy: 0.72 - ETA: 3:46 - loss: 2.0105 - accuracy: 0.74 - ETA: 3:37 - loss: 2.0112 - accuracy: 0.74 - ETA: 3:27 - loss: 2.0045 - accuracy: 0.72 - ETA: 3:17 - loss: 2.0096 - accuracy: 0.70 - ETA: 3:08 - loss: 2.0031 - accuracy: 0.70 - ETA: 2:59 - loss: 1.9970 - accuracy: 0.70 - ETA: 2:49 - loss: 1.9923 - accuracy: 0.69 - ETA: 2:39 - loss: 1.9839 - accuracy: 0.69 - ETA: 2:28 - loss: 1.9802 - accuracy: 0.68 - ETA: 2:17 - loss: 1.9735 - accuracy: 0.67 - ETA: 2:05 - loss: 1.9660 - accuracy: 0.66 - ETA: 1:53 - loss: 1.9630 - accuracy: 0.66 - ETA: 1:41 - loss: 1.9628 - accuracy: 0.66 - ETA: 1:30 - loss: 1.9527 - accuracy: 0.66 - ETA: 1:19 - loss: 1.9483 - accuracy: 0.67 - ETA: 1:09 - loss: 1.9416 - accuracy: 0.66 - ETA: 58s - loss: 1.9348 - accuracy: 0.6733 - ETA: 48s - loss: 1.9289 - accuracy: 0.664 - ETA: 38s - loss: 1.9312 - accuracy: 0.656 - ETA: 28s - loss: 1.9249 - accuracy: 0.648 - ETA: 18s - loss: 1.9236 - accuracy: 0.635 - ETA: 9s - loss: 1.9200 - accuracy: 0.628 - 347s 2s/step - loss: 1.9131 - accuracy: 0.6389 - val_loss: 1.7379 - val_accuracy: 0.6667\n",
      "Epoch 5/5\n",
      "180/180 [==============================] - ETA: 5:07 - loss: 1.5979 - accuracy: 1.00 - ETA: 4:31 - loss: 1.6266 - accuracy: 0.90 - ETA: 4:13 - loss: 1.7057 - accuracy: 0.80 - ETA: 4:01 - loss: 1.7221 - accuracy: 0.75 - ETA: 3:50 - loss: 1.7415 - accuracy: 0.68 - ETA: 3:42 - loss: 1.7642 - accuracy: 0.66 - ETA: 3:33 - loss: 1.7949 - accuracy: 0.65 - ETA: 3:26 - loss: 1.8013 - accuracy: 0.67 - ETA: 3:17 - loss: 1.8247 - accuracy: 0.64 - ETA: 3:10 - loss: 1.8389 - accuracy: 0.64 - ETA: 3:02 - loss: 1.8538 - accuracy: 0.67 - ETA: 2:54 - loss: 1.8624 - accuracy: 0.68 - ETA: 2:46 - loss: 1.8924 - accuracy: 0.64 - ETA: 2:39 - loss: 1.9119 - accuracy: 0.62 - ETA: 2:31 - loss: 1.9224 - accuracy: 0.64 - ETA: 2:24 - loss: 1.9427 - accuracy: 0.63 - ETA: 2:16 - loss: 1.9539 - accuracy: 0.63 - ETA: 2:09 - loss: 1.9722 - accuracy: 0.62 - ETA: 2:01 - loss: 1.9807 - accuracy: 0.62 - ETA: 1:54 - loss: 1.9853 - accuracy: 0.63 - ETA: 1:47 - loss: 1.9943 - accuracy: 0.63 - ETA: 1:40 - loss: 1.9976 - accuracy: 0.64 - ETA: 1:33 - loss: 2.0054 - accuracy: 0.63 - ETA: 1:26 - loss: 2.0159 - accuracy: 0.61 - ETA: 1:18 - loss: 2.0173 - accuracy: 0.62 - ETA: 1:11 - loss: 2.0227 - accuracy: 0.62 - ETA: 1:04 - loss: 2.0265 - accuracy: 0.62 - ETA: 57s - loss: 2.0349 - accuracy: 0.6143 - ETA: 50s - loss: 2.0365 - accuracy: 0.606 - ETA: 43s - loss: 2.0426 - accuracy: 0.606 - ETA: 35s - loss: 2.0448 - accuracy: 0.600 - ETA: 28s - loss: 2.0535 - accuracy: 0.593 - ETA: 21s - loss: 2.0558 - accuracy: 0.593 - ETA: 14s - loss: 2.0593 - accuracy: 0.582 - ETA: 7s - loss: 2.0576 - accuracy: 0.588 - 266s 1s/step - loss: 2.0581 - accuracy: 0.5944 - val_loss: 2.2703 - val_accuracy: 0.7000\n",
      "40/40 [==============================] - ETA:  - 15s 373ms/step\n",
      "[2.2715250492095946, 0.7250000238418579]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "\n",
    "from keras.engine.topology import Layer\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "#from sklearn.utils import shuffle\n",
    "    \n",
    "model = get_siamese_model((200,500,1))\n",
    "optimizer = Adam(lr=0.001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "print(\"starting training process\")\n",
    "print(\"...............................\")\n",
    "#t_start = time.time()\n",
    "model.fit([x1_train,x2_train],y_train,verbose=1,batch_size=5,validation_data=[[x1_val,x2_val],y_val],epochs = 5,shuffle = True)\n",
    "scores = model.evaluate([x1_test,x2_test],y_test,verbose=1)\n",
    "print(scores)\n",
    "model.save('siamese_net.h5')\n",
    "#t_stop = (time.time()-t_start())\n",
    "#print(t_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loss():\n",
    "    in_tensor = tf.placeholder(tf.float32, (None, 3))\n",
    "    labels = tf.placeholder(tf.int32, None, 1)\n",
    "    model = Model(in_tensor, labels)\n",
    "    sess = tf.Session()\n",
    "    loss = sess.run(model.loss, feed_dict={\n",
    "    in_tensor:np.ones(1, 3),\n",
    "    labels:[[1]]})\n",
    "    assert (loss!= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN:\n",
    "    def _init_(self, z_vector, true_images):\n",
    "    # Pretend these are implemented.\n",
    "        with tf.variable_scope(\"gen\"):\n",
    "            self.make_geneator(z_vector)\n",
    "        with tf.variable_scope(\"des\"):\n",
    "            self.make_descriminator(true_images)\n",
    "        opt = tf.AdamOptimizer()\n",
    "        train_descrim = opt.minimize(self.descrim_loss)\n",
    "        train_gen = opt.minimize(self.gen_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_gen_training():\n",
    "    model = Model\n",
    "    sess = tf.Session()\n",
    "    gen_vars = tf.get_collection(tf.GraphKeys.VARIABLES, scope='gen')\n",
    "    des_vars = tf.get_collection(tf.GraphKeys.VARIABLES, scope='des')\n",
    "    before_gen = sess.run(gen_vars)\n",
    "    before_des = sess.run(des_vars)\n",
    "    # Train the generator.\n",
    "    sess.run(model.train_gen)\n",
    "    after_gen = sess.run(gen_vars)\n",
    "    after_des = sess.run(des_vars)\n",
    "    # Make sure the generator variables changed.\n",
    "    for b,a in zip(before_gen, after_gen):\n",
    "        assert(a != b).any()\n",
    "  # Make sure descriminator did NOT change.\n",
    "    for b,a in zip(before_des, after_des):\n",
    "        assert(a == b).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytestNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading pytest-5.4.3-py3-none-any.whl (248 kB)\n",
      "Collecting py>=1.5.0\n",
      "  Downloading py-1.9.0-py2.py3-none-any.whl (99 kB)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\jayalakshmi\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from pytest) (0.1.9)\n",
      "Requirement already satisfied: packaging in c:\\users\\jayalakshmi\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from pytest) (20.3)\n",
      "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in c:\\users\\jayalakshmi\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from pytest) (1.5.0)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in c:\\users\\jayalakshmi\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from pytest) (0.13.1)\n",
      "Requirement already satisfied: atomicwrites>=1.0; sys_platform == \"win32\" in c:\\users\\jayalakshmi\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from pytest) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\jayalakshmi\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from pytest) (19.3.0)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in c:\\users\\jayalakshmi\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from pytest) (0.4.3)\n",
      "Collecting more-itertools>=4.0.0\n",
      "  Downloading more_itertools-8.4.0-py3-none-any.whl (43 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\jayalakshmi\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from packaging->pytest) (2.4.7)\n",
      "Requirement already satisfied: six in c:\\users\\jayalakshmi\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from packaging->pytest) (1.14.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\jayalakshmi\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest) (3.1.0)\n",
      "Installing collected packages: py, more-itertools, pytest\n",
      "Successfully installed more-itertools-8.4.0 py-1.9.0 pytest-5.4.3\n"
     ]
    }
   ],
   "source": [
    "pip install pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TUNING PROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import kerastuner as kt\n",
    "from kerastuner import HyperModel\n",
    "from kerastuner.tuners import Hyperband\n",
    "from kerastuner.applications import HyperResNet\n",
    "from kerastuner.tuners import RandomSearch, Hyperband, BayesianOptimization\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training process\n",
      "************************\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-64319b4eb742>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"************************\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;31m#t_start = time.time()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx1_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx2_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx1_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx2_val\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx1_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx2_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from kerastuner.engine.hyperparameters import HyperParameters as hp\n",
    "#importing HyperParameters as hp\n",
    "\n",
    "def get_siamese_model(input_shape):\n",
    "    input_shape = (200,500,1)\n",
    "    left_input=Input(input_shape)\n",
    "    right_input=Input(input_shape)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32,(3,3), activation='relu', input_shape=input_shape,\n",
    "                    kernel_regularizer=l2(0.01),bias_regularizer=l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(\n",
    "            Dropout(rate=hp.Float(\n",
    "                    'dropout_1',\n",
    "                    min_value=0.0,\n",
    "                    max_value=0.5,\n",
    "                    default=0.25,\n",
    "                    step=0.05,\n",
    "                    \n",
    "                \n",
    "            )))\n",
    "    model.add(tf.keras.layers.MaxPooling2D())\n",
    "    model.add(Conv2D(64,(4,4), activation='relu',\n",
    "                    kernel_regularizer=l2(0.01),bias_regularizer=l2(0.01)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(\n",
    "        Dropout(\n",
    "                rate=hp.Float(\n",
    "                    'dropout2',\n",
    "                    min_value=0.0,\n",
    "                    max_value=0.5,\n",
    "                    default=0.25,\n",
    "                    step=0.05,\n",
    "                )\n",
    "            )\n",
    "    )\n",
    "    model.add(tf.keras.layers.MaxPooling2D())\n",
    "    for i in range(hp.Int('n_layers',1,4)):\n",
    "        model.add(Conv2D(hp.Int(f'conv_{i}_units', \n",
    "                    min_value=32,\n",
    "                    max_value=256,\n",
    "                    step=32),(4,4)))\n",
    "        model.add(Activation('relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(\n",
    "        Dropout(\n",
    "            rate=hp.Float(\n",
    "                    'dropout_3',\n",
    "                    min_value=0.0,\n",
    "                    max_value=0.5,\n",
    "                    default=0.25,\n",
    "                    step=0.05,\n",
    "            )))\n",
    "    model.add(tf.keras.layers.MaxPooling2D())\n",
    "    model.add(Conv2D(128,(9,9), activation='relu',\n",
    "                    kernel_regularizer=l2(0.01),bias_regularizer=l2(0.01)))\n",
    "    model.add(tf.keras.layers.MaxPooling2D())\n",
    "    model.add(Flatten())\n",
    "    model.add(\n",
    "            Dense(\n",
    "                units=hp.Int(\n",
    "                    'units',\n",
    "                    min_value=32,\n",
    "                    max_value=512,\n",
    "                    step=32,\n",
    "                    default=128\n",
    "                ),\n",
    "                activation=hp.Choice(\n",
    "                    'dense_activation',\n",
    "                    values=['relu', 'tanh', 'sigmoid'],\n",
    "                    default='relu'\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    model.add(Dense(1024,activation='sigmoid',kernel_regularizer=l2(0.01),bias_regularizer=l2(0.01)))\n",
    "    \n",
    "    encoded_l=model(left_input)\n",
    "    encoded_r=model(right_input)\n",
    "    \n",
    "    L1_layer = tf.keras.layers.Lambda(lambda tensors:K.abs(tensors[0]-tensors[1]))\n",
    "    L1_distance=L1_layer([encoded_l,encoded_r])\n",
    "    \n",
    "    prediction=tf.keras.layers.Dense(1,activation='sigmoid')(L1_distance)\n",
    "    \n",
    "    siamese_net1 = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "    \n",
    "    siamese_net1.compile(\n",
    "     optimizer=tf.keras.optimizers.Adam(\n",
    "                hp.Float(\n",
    "                    'learning_rate',\n",
    "                    min_value=1e-4,\n",
    "                    max_value=1e-2,\n",
    "                    sampling='LOG',\n",
    "                    default=1e-3\n",
    "                )\n",
    "            ),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "    return siamese_net1\n",
    "\n",
    "\n",
    "print(\"starting training process\")\n",
    "print(\"************************\")\n",
    "#t_start = time.time()\n",
    "model.fit([x1_train,x2_train],y_train,verbose=1,batch_size=5,validation_data=[[x1_val,x2_val],y_val],epochs = 5,shuffle = True)\n",
    "scores = model.evaluate([x1_test,x2_test],y_test,verbose=1)\n",
    "print(scores)\n",
    "#model.save('siamese_net.h5')\n",
    "#t_stop = (time.time()-t_start())\n",
    "#print(t_stop)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dense(units=hp.Int('units',\n",
    "                                        min_value=32,\n",
    "                                        max_value=512,\n",
    "                                        step=32),\n",
    "                           activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate',\n",
    "                      values=[1e-2, 1e-3, 1e-4])),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    #y_binary = to_categorical(180)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project .\\untitled_project\\oracle.json\n"
     ]
    }
   ],
   "source": [
    "tuner = RandomSearch(\n",
    "    get_siamese_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=3,\n",
    "    executions_per_trial=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuner search summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Search space summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Default search space size: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">units (Int)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-max_value: 512</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-min_value: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-sampling: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-step: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">learning_rate (Choice)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-ordered: True</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-values: [0.01, 0.001, 0.0001]</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project hyperband\\siamese\\oracle.json\n"
     ]
    }
   ],
   "source": [
    "from kerastuner.tuners import Hyperband\n",
    "from kerastuner import HyperModel\n",
    "\n",
    "\n",
    "HYPERBAND_MAX_EPOCHS = 2\n",
    "MAX_TRIALS = 5\n",
    "EXECUTION_PER_TRIAL = 1\n",
    "\n",
    "tuner = Hyperband(\n",
    "    hypermodel,\n",
    "    max_epochs=HYPERBAND_MAX_EPOCHS,\n",
    "    objective='val_accuracy',\n",
    "    executions_per_trial=EXECUTION_PER_TRIAL,\n",
    "    directory='hyperband',\n",
    "    project_name='siamese'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Results summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Results in hyperband\\siamese</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Showing 10 best trials</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Objective(name='val_accuracy', direction='max')</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#best model\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
